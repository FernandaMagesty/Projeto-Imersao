{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqvbylMV097xxtYq33C7Ho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandaMagesty/Projeto-Imersao/blob/main/Quick_Support.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalando o SDK do Google\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "_3EMUHbAW5My"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurações iniciais\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('Chave_secreta')\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "Wfad1KpwXUj6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponiveis\n"
      ],
      "metadata": {
        "id": "tEcly2fPX0BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "C1_8lwPxXuia",
        "outputId": "5aaf6062-a5e4-453d-b999-da239604708a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config ={\n",
        "\"candidate_count\":1,\n",
        "\"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "iFc646jVbps2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }\n"
      ],
      "metadata": {
        "id": "o3SOwSm3dBLL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo\n"
      ],
      "metadata": {
        "id": "banNvhwznJ-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro-vision-latest',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)\n",
        "\n"
      ],
      "metadata": {
        "id": "nUvVp0BoAXAh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('Descreva o seu problema?')\n",
        "response.text"
      ],
      "metadata": {
        "id": "Nlm4m77JIXox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7PgrPeYmIm0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gzoa8zmL5-O",
        "outputId": "21ede791-6b30-4a82-d40a-bc746409140a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar o NLTK e baixar o recurso \"punkt\"\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Função para processar a entrada do usuário\n",
        "def processar_entrada(texto_usuario):\n",
        "  # Tokenização da entrada\n",
        "  tokens = nltk.word_tokenize(texto_usuario)\n",
        "  # ... (mais processamento)\n",
        "  return tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwxqYEaqMTnY",
        "outputId": "e0355d11-641b-4046-f4fb-4da66ab338b3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para processar a entrada do usuário\n",
        "import nltk\n",
        "\n",
        "def processar_entrada(texto_usuario):\n",
        "  # Tokenização da entrada\n",
        "  tokens = nltk.word_tokenize(texto_usuario)\n",
        "  # Extração de entidades nomeadas (opcional)\n",
        "  # entidades = nltk.ne_chunk(tokens)\n",
        "  # ... (mais processamento de acordo com suas necessidades)\n",
        "  return tokens\n",
        "\n",
        "# Exemplo de uso\n",
        "entrada_usuario = input(\"Descreva seu problema:\")\n",
        "tokens = processar_entrada(entrada_usuario)\n",
        "\n",
        "# ... (use os tokens para gerar o prompt para o modelo) ..."
      ],
      "metadata": {
        "id": "t9RQGvaYLSDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Carregar um modelo de linguagem (ex: inglês)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extrair_entidades(texto):\n",
        "  doc = nlp(texto)\n",
        "  entidades = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "  return entidades\n",
        "\n",
        "# Exemplo de uso\n",
        "texto = \"Meu teclado não está funcionando no Windows 10.\"\n",
        "entidades = extrair_entidades(texto)\n",
        "print(entidades)  # Output: [('teclado', 'DEVICE'), ('Windows 10', 'OS')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT6xSj7nNUCd",
        "outputId": "6d0f8f86-0e69-42aa-e415-c415dc3c422d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Meu', 'PERSON'), ('no Windows 10', 'NORP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Refinamento do Processamento de Entrada:\n"
      ],
      "metadata": {
        "id": "qVXzYEpRNq6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "# Baixar recursos do NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "# Carregar modelo spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Substitua pelo modelo de sua preferência\n",
        "\n",
        "def processar_entrada(texto):\n",
        "    # Tokenização\n",
        "    tokens = nltk.word_tokenize(texto)\n",
        "\n",
        "    # Reconhecimento de entidades nomeadas (NER) com NLTK\n",
        "    entidades_nltk = nltk.ne_chunk(nltk.pos_tag(tokens))\n",
        "\n",
        "    # NER com spaCy\n",
        "    doc = nlp(texto)\n",
        "    entidades_spacy = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    # Classificação de problemas (exemplo simples baseado em palavras-chave)\n",
        "    problema_categoria = None\n",
        "    if any(palavra in tokens for palavra in [\"tela\", \"azul\", \"congelou\"]):\n",
        "        problema_categoria = \"Sistema operacional\"\n",
        "    elif any(palavra in tokens for palavra in [\"internet\", \"lenta\", \"wifi\"]):\n",
        "        problema_categoria = \"Rede\"\n",
        "    # ... (adicione mais regras para outras categorias)\n",
        "\n",
        "    # Análise de sentimento (exemplo com TextBlob)\n",
        "    from textblob import TextBlob\n",
        "    sentimento = TextBlob(texto).sentiment.polarity  # Valor entre -1 (negativo) e 1 (positivo)\n",
        "\n",
        "    return tokens, entidades_nltk, entidades_spacy, problema_categoria, sentimento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4o9Nf-UNr5f",
        "outputId": "47787ac6-c65f-4529-840a-32a6882c9138"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construindo um Sistema de Diálogo:"
      ],
      "metadata": {
        "id": "cArjYKlBNzA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "# Baixar recursos do NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "# Carregar modelo spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Substitua pelo modelo de sua preferência\n",
        "\n",
        "def processar_entrada(texto):\n",
        "    # Tokenização\n",
        "    tokens = nltk.word_tokenize(texto)\n",
        "\n",
        "    # Reconhecimento de entidades nomeadas (NER) com NLTK\n",
        "    entidades_nltk = nltk.ne_chunk(nltk.pos_tag(tokens))\n",
        "\n",
        "    # NER com spaCy\n",
        "    doc = nlp(texto)\n",
        "    entidades_spacy = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    # Classificação de problemas (exemplo simples baseado em palavras-chave)\n",
        "    problema_categoria = None\n",
        "    if any(palavra in tokens for palavra in [\"tela\", \"azul\", \"congelou\"]):\n",
        "        problema_categoria = \"Sistema operacional\"\n",
        "    elif any(palavra in tokens for palavra in [\"internet\", \"lenta\", \"wifi\"]):\n",
        "        problema_categoria = \"Rede\"\n",
        "    # ... (adicione mais regras para outras categorias)\n",
        "\n",
        "    # Análise de sentimento (exemplo com TextBlob)\n",
        "    from textblob import TextBlob\n",
        "    sentimento = TextBlob(texto).sentiment.polarity  # Valor entre -1 (negativo) e 1 (positivo)\n",
        "\n",
        "    return tokens, entidades_nltk, entidades_spacy, problema_categoria, sentimento\n",
        "# Use code with caution.\n",
        "# Python\n",
        "# Construindo um Sistema de Diálogo:\n",
        "# Exemplo de estrutura para armazenar contexto\n",
        "contexto_usuario = {\n",
        "    \"problema\": None,\n",
        "    \"categoria\": None,\n",
        "    \"tentativas\": [],\n",
        "    \"sentimento\": None\n",
        "}\n",
        "\n",
        "def atualizar_contexto(texto_usuario):\n",
        "    # Processar a entrada e extrair informações\n",
        "    tokens, entidades_nltk, entidades_spacy, categoria, sentimento = processar_entrada(texto_usuario)\n",
        "\n",
        "    # Atualizar o contexto\n",
        "    contexto_usuario[\"problema\"] = texto_usuario\n",
        "    contexto_usuario[\"categoria\"] = categoria\n",
        "    contexto_usuario[\"sentimento\"] = sentimento\n",
        "    # ... (adicione mais informações conforme necessário)\n",
        "\n",
        "def gerar_resposta(contexto):\n",
        "    # Utilize o contexto para formular a resposta\n",
        "    if contexto[\"categoria\"] == \"Sistema operacional\":\n",
        "        if \"reiniciar\" not in contexto[\"tentativas\"]:\n",
        "            resposta = \"Tente reiniciar o computador e veja se o problema persiste.\"\n",
        "            contexto[\"tentativas\"].append(\"reiniciar\")\n",
        "        else:\n",
        "            resposta = \"O problema parece ser mais complexo. Recomendo consultar um técnico ou pesquisar em fóruns de suporte.\"\n",
        "    # ... (adicione mais condições para outras categorias e cenários)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdva7AisN5i8",
        "outputId": "815dc2d5-a46e-40aa-ef26-9e0a26e5a7fe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Suporte a Múltiplos Idiomas"
      ],
      "metadata": {
        "id": "7dFLIUkJQRni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def traduzir_texto(texto, idioma_origem, idioma_destino):\n",
        "  # Utilize a API de tradução escolhida para traduzir o texto\n",
        "  # ...\n",
        "  return texto_traduzido\n",
        "\n",
        "def processar_entrada(texto_usuario, idioma_usuario):\n",
        "  # Traduzir o texto do usuário para o idioma principal do chatbot\n",
        "  texto_traduzido = traduzir_texto(texto_usuario, idioma_usuario, \"en\")  # Exemplo: traduzir para inglês\n",
        "  # Processar o texto traduzido (tokenização, NER, etc.)\n",
        "  # ...\n",
        "  return informações_extraídas\n",
        "\n",
        "def gerar_resposta(contexto, idioma_usuario):\n",
        "  # ... (gerar resposta no idioma principal do chatbot)\n",
        "  resposta_traduzida = traduzir_texto(resposta, \"en\", idioma_usuario)  # Traduzir a resposta para o idioma do usuário\n",
        "  return resposta_traduzida"
      ],
      "metadata": {
        "id": "J7_-0D3CR8OB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Personalização"
      ],
      "metadata": {
        "id": "31UvspsDSIT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta(contexto, preferencias_usuario):\n",
        "  # ... (gerar resposta base)\n",
        "  if preferencias_usuario[\"detalhes\"] == \"alto\":\n",
        "    resposta += \" ...\"  # Adicionar mais detalhes à resposta\n",
        "  if preferencias_usuario[\"estilo\"] == \"informal\":\n",
        "    resposta = transformar_texto_para_informal(resposta)\n",
        "  return respost"
      ],
      "metadata": {
        "id": "KrPGjdBZSSDQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando contexto"
      ],
      "metadata": {
        "id": "zpRMPyzZUQIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta(contexto):\n",
        "    # Lógica para gerar a resposta com base no contexto\n",
        "    if contexto[\"categoria\"] == \"Sistema operacional\":\n",
        "        resposta = \"Problemas no sistema operacional podem ter várias causas. Você já tentou reiniciar o computador?\"\n",
        "    elif contexto[\"categoria\"] == \"Rede\":\n",
        "        resposta = \"Problemas de rede podem ser causados por diversos fatores. Você está conectado à internet via Wi-Fi ou cabo?\"\n",
        "    else:\n",
        "        resposta = \"Ainda estou aprendendo e não tenho informações suficientes para ajudar com esse problema específico.\"\n",
        "\n",
        "    return resposta  # Retorna a resposta gerada"
      ],
      "metadata": {
        "id": "F6wRJe_pU__9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coletando Feedback dos Usuários para o Chatbot"
      ],
      "metadata": {
        "id": "v73eEyghSsz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pedir_feedback(contexto):\n",
        "    resposta = \"Isso ajudou a resolver seu problema? (sim/não)\"\n",
        "    return resposta\n",
        "\n",
        "# ... (no loop principal da conversa)\n",
        "\n",
        "resposta_chatbot = gerar_resposta(contexto)\n",
        "resposta_chatbot += \"\\n\\n\" + pedir_feedback(contexto)\n",
        "print(resposta_chatbot)\n",
        "\n",
        "feedback_usuario = input().lower()\n",
        "if feedback_usuario == \"sim\":\n",
        "    print(\"Fico feliz em ter ajudado! 😊\")\n",
        "elif feedback_usuario == \"não\":\n",
        "    print(\"Sinto muito que não pude ajudar. 😔 Posso tentar algo mais?\")\n",
        "    # ... (implemente lógica para lidar com feedback negativo)\n",
        "else:\n",
        "    print(\"Desculpe, não entendi sua resposta.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT6zfJzPTw5X",
        "outputId": "354827a1-14da-4d61-973f-634f06804a07"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ainda estou aprendendo e não tenho informações suficientes para ajudar com esse problema específico.\n",
            "\n",
            "Isso ajudou a resolver seu problema? (sim/não)\n",
            "sim\n",
            "Fico feliz em ter ajudado! 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando uma Interface Gráfica Interativa para o Chatbot"
      ],
      "metadata": {
        "id": "S8yJlpm-Vhy0"
      }
    }
  ]
}